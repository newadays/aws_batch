#create the environment
aws batch create-compute-environment --cli-input-json file://compute_env.json --region {region}
aws batch register-job-definition --job-definition-name mapper_job_def --cli-input-json file://job_definition.json --region {region}
aws batch create-job-queue --cli-input-json file://job_queue.json --region {region}
aws batch submit-job --cli-input-json file://submit_job.json --region {region}

#build your docker image
cd aws_batch/map_reduce/mappper/

docker build -t awsbatch/mapper .

#Run the docker locally as a test
docker run -it --rm \
  -e "HOME=/home" \
  -e s3_input_dir='s3://mybucket/data/' \
  -e s3_output_dir='s3://mybucket/result/' \
  -e input_file='mobydick.txt' \
  -v $HOME/.aws:/home/.aws \
  awsbatch/mapper
  
#Login into ECR repository and push the image
aws ecr get-login --no-include-email --region us-east-1

docker tag awsbatch/mapper:latest {arn}.dkr.ecr.{region_name}.amazonaws.com/awsbatch/mapper:latest

docker push {arn}.dkr.{region_name}.amazonaws.com/awsbatch/mapper:latest
